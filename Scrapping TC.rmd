---
title: "Scrapping TC"
author: "Jan Dimter Stransky, Cristobal Ortiz y Martín Venegas"
date: "10/24/2020"
output: html_document
---

# Web Scrapping TC
Descripción: Este RMarkdown realizará la técnica de web-scrapping a la página del Tribunal Constitucional. Se recuperará la información de las sentencias que por materia tengan *Control de constitucionalidad de leyes o tratados (Artículo 93 Nº1)* o *Constitucionalidad de proyectos de ley (Artículo 93 Nº3*. Se acotará a aquellas causas que hayan sido requerimientos por parte de parlamentarios.


```{r Configuración, message=FALSE, warning=FALSE}
# Configuración del .rmd y carga de paquetes.
knitr::opts_chunk$set(echo = FALSE)
## Paquetes
library(tidyverse)
# Parsing of HTML/XML files
library(rvest)
# String manipulation
library(stringr)
# Verbose regular expressions
library(rebus)
# Eases DateTime manipulation
library(lubridate)
```

## Operación
A continuación se desarrolla el web scrapping:
```{r Scrapping Manual, echo=True}
#Carga de la web
TC_link <-'https://www.tribunalconstitucional.cl/sentencias/busqueda-avanzada'
#Lectura del HTML
TC_web <- read_html(TC_link)
#Carga del formulario y relleno de búsqueda
form <- html_form(TC_web)[[3]]
form2 <- set_values(form, materia= "4", texto="Requerimiento")
form2$url <- ""
TC_session <- html_session("https://www.tribunalconstitucional.cl/sentencias/busqueda-avanzada")
TC_conform <- submit_form(session=TC_session, form=form2)
#Lectura del resultado
TC_html <- read_html(TC_conform)
#Extracción tabla de resultados
TC_table <- html_table(TC_conform, fill=TRUE)[[2]]

páginas <-TC_html %>% html_nodes("center a") %>% html_text()%>% .[-length(.)]


txt<-"Requerimiento"
cat<-"4"

  TC_link <-'https://www.tribunalconstitucional.cl/sentencias/busqueda-avanzada'
  TC_web <- read_html(TC_link)
  form_base <- html_form(TC_web)[[3]]
  form_beta <- set_values(form_base, materia= cat, texto=txt)
  TC_session <- html_session(TC_link)
  TC_conform <- submit_form(session=TC_session, form=form_beta)
  TC_resultado_beta <- read_html(TC_conform)
  
   paginas <-TC_resultado_beta %>% html_nodes("center a") %>% html_text()%>% .[-length(.)]
  #Lista con múltiples forms base
  forms_mult_base<- list(form_base)[rep(1,length(paginas))]
  
 #Creación lista con n formularios rellenados con el número de páginas
  forms_mult_rell <- list()  # 1. output
  for( i in seq_along(paginas)){
    forms_mult_rell[[i]] <- set_values(form_base, materia= cat, texto=txt, pagina =i)}
  submit_forms<-lapply(forms_mult_rell,submit_form,session=TC_session)
  read_results<-lapply(submit_forms,read_html)
  
   links_p1 <- html_nodes(read_results[[1]], "div tr td a") %>% html_attr("href")
   links_p1 <- links_p1[c(4,8,16,21,27,32,36,41,46,50)]
   links_p2 <- html_nodes(read_results[[2]], "div tr td a") %>% html_attr("href")
   links_p2 <- links_p2[c(4,8,12,16,20,24,28,32,36,40)]
   links_p3 <- html_nodes(read_results[[3]], "div tr td a") %>% html_attr("href")
   links_p3 <- links_p3[c(4,8,12,16,20,24,28,32,36,40)]
   links_p4 <- html_nodes(read_results[[4]], "div tr td a") %>% html_attr("href")
   links_p4 <- links_p4[c(4,8,12,16,20,24,28,32,36,40)]
   links_p5 <- html_nodes(read_results[[5]], "div tr td a") %>% html_attr("href")
   links_p5 <- links_p5[c(4,8,12,16,20,24,28,32,36,40)]
   links_p6 <- html_nodes(read_results[[6]], "div tr td a") %>% html_attr("href")
   links_p6 <- links_p6[c(4,8,12,16,20,24,28,32,36,40)]
   links_p7 <- html_nodes(read_results[[7]], "div tr td a") %>% html_attr("href")
   links_p7 <- links_p7[c(4,8,12,16,20,24,28,32,36,40)]
   links_p8 <- html_nodes(read_results[[8]], "div tr td a") %>% html_attr("href")
   links_p8 <- links_p8[c(4,8,12,16,20,24,28,32,36,40)]
   links_p9 <- html_nodes(read_results[[9]], "div tr td a") %>% html_attr("href")
   links_p9 <- links_p9[c(4,8,12,16,20,24,28,32,36,40)]
   
  links <- c(links_p1, links_p2, links_p3, links_p4, links_p5, links_p6, links_p7, links_p8, links_p9)
```

```{r Scrapping Create Function, echo=True}
#Función superior (devuelve dato en formato tabla)

# Esta funcion rellena el formulario de Busqueda Avanzada para la pagina del Tribunal Constitucional a partir de dos argumentos: el numero de la materia y una palabra clave. Se elabora para utilizar a futuro.

scrapTC <- function (cat,txt) {
  TC_link <-'https://www.tribunalconstitucional.cl/sentencias/busqueda-avanzada'
  TC_web <- read_html(TC_link)
  form_base <- html_form(TC_web)[[3]]
  form_beta <- set_values(form_base, materia= cat, texto=txt)
  TC_session <- html_session(TC_link)
  TC_conform <- submit_form(session=TC_session, form=form_beta)
  TC_resultado_beta <- read_html(TC_conform)
  
  #Scrapeo número de páginas
  paginas <-TC_resultado_beta %>% html_nodes("center a") %>% html_text()%>% .[-length(.)]
  #Lista con múltiples forms base
  forms_mult_base<- list(form_base)[rep(1,length(paginas))]
  
 #Creación lista con n formularios rellenados con el número de páginas
  forms_mult_rell <- list()  # 1. output
  for( i in seq_along(paginas)){
    forms_mult_rell[[i]] <- set_values(form_base, materia= cat, texto=txt, pagina =i)}
  submit_forms<-lapply(forms_mult_rell,submit_form,session=TC_session)
  read_results<-lapply(submit_forms,read_html)
  extracc_tablas2<- lapply(read_results,html_nodes,css="form table:last-child table")
  extracc_tablas_final<- lapply(extracc_tablas2,html_table,fill=TRUE,header=TRUE)
  prueba1 <-unlist(extracc_tablas_final,recursive = FALSE)
  #largo_lista <- length(prueba1)
  tabla_síntesis<-Reduce(bind_rows, prueba1)
  return(tabla_síntesis)
}
#Ejemplo, buscaremos sentencias relativas a
#Materia: Control de constitucionalidad de leyes y tratados (Art.19 nº1) ("2")
#Palabra clave: "sexual"
Ejemplo <-scrapTC("2","sexual")
Ejemplo
```

```{r Scrappear Requerimientos}
# Aplicar la funcion elaborada para categoria "Constitucionalidad de Proyectos de Ley (Art 93 N3)
# Palabra clave: Requerimiento
Req <- scrapTC("4", "Requerimiento")

# Modificar dataset
Req <- Req[,-c(3,5)] # Eliminar columnas innecesarias
Req$links <- links # Agregar columna de links creada semi-manualmente
Req$links <- paste("https://www.tribunalconstitucional.cl", Req$links, sep = "") # Agregar pagina para leer links

# No se me ocurre una forma para que la funcion anterior no aplique a las row 6, 7 y 8, asique vuelvo a cambiar de nombre

Req$links[6] <- "http://www.tribunalconstitucional.cl/wp-content/uploads/fallo_rol_2935_glosa.html"
Req$links[7] <- "http://www.tribunalconstitucional.cl/wp-content/uploads/Rol2787.html"
Req$links[8] <- "http://www.tribunalconstitucional.cl/wp-content/uploads/SRol2777-15-CPT.html"


# Extraer parrafo en donde se menciona a los Senadores que presenan el requerimiento.

# Funcion para crear bases con los parrafos de las Sentencias
createS <- function(base, linkrow) {
  base <- read_html(Req$links[linkrow]) %>% # Leer link
  html_nodes("p") %>% # Etiquetas
  html_text()
  return(base)
}

# Funcion para buscar el parrafo que incluye a los Senadores y Diputados que presentan el Requerimiento. 

# Palabra clave: miembros (ya que para presentar un Requerimiento se necesita al menos un cuarto de la corporacion)

findreq <- function(base) {
  return(grep("miembros", base))
}

# For para crear lista con los parrafos extraidos
parrafos <- list()
Ss <- 1:90

for( i in seq_along(Ss)){
    parrafos[[i]] <- createS("S", i)}

# Buscar los parrafos con la palabra "miembros" en ella.
lapply(parrafos, findreq)

# Comprobar

parrafos[[1]][15]
parrafos[[2]][8]
parrafos[[3]][7]
parrafos[[4]][8]
parrafos[[5]][7]
parrafos[[6]][3]
parrafos[[7]][56]
parrafos[[8]][4]
parrafos[[9]][6]
parrafos[[19]][10]

```

